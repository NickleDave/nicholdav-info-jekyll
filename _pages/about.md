---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

## the quick version
I am currently a machine intelligence engineer with
[Embedded Intelligence](https://www.linkedin.com/company/embedintel/),
a start-up in the DC area, where I work on adversarial machine learning
([GARD](https://www.darpa.mil/program/guaranteeing-ai-robustness-against-deception),
[RED](https://beta.sam.gov/opp/258cc833c18749de87aba9c129ee2205/view))
and signal restoration.
Generally speaking, I do research in the areas of
artificial intelligence, cognition, and neuroscience.

## computational modeling of visual search behavior
During my post-doctoral fellowship at Emory University in Atlanta, Georgia,
I worked with [Astrid Prinz](http://www.biology.emory.edu/research/Prinz/index.html)
in the [Biology department](http://www.biology.emory.edu/),
on brain-inspired algorithms for continual machine learning,
as part of a [DARPA program](https://www.darpa.mil/news-events/2017-03-16).
The Prinz lab provided neuroscience expertise for members of our team
working on algorithms for goal-driven perception.
My goal for this project was to understand visual search:
how does our brain solve the problem of finding an object we're looking for?
For more on this research, please see this section of my GitHub profile page:  
<https://github.com/NickleDave#visual-search-and-visual-attention>.

## machine learning and data science tools for studying vocalizations
My work in applied machine learning focuses mainly on automated annotation of
birdsong and other vocalizations.
Most recently, I collaborated with [Yarden Cohen](https://yardencsgithub.github.io/)
and [Tim Gardner](http://www.bu.edu/biology/people/profiles/tim-gardner/)
to develop a neural network that learns
how to annotate birdsong from spectrograms:  
<https://github.com/yardencsGitHub/tweetynet>.  
For other related libraries and tools I develop and maintain, please see
this section of my GitHub profile page:  
<https://github.com/NickleDave#data-science-tools-for-birdsong-and-other-vocalizations>

## neuroscience of motor learning
I began developing software tools for studying vocalizations during my graduate studies in
[Sam Sober's lab](http://www.biology.emory.edu/research/Sober/Home.html) at Emory.
The Sober lab studies motor learning, broadly defined, including vocal learning in songbirds.
Songbirds provide neuroscience an excellent model system to understand
how the brain learns and produces speech and similar motor skills,
like playing guitar or swinging a bat to hit a baseball.
My [dissertation work](https://open.library.emory.edu/publications/emory%3Atrghv/)
in the Sober lab showed that connections which
are known to be important for learning motor skills in humans and other
mammals are also found in regions of the songbird brain
that are important for learning song.
For the [published paper](https://onlinelibrary.wiley.com/doi/abs/10.1002/cne.24428)
and related works, please see my
[Google Scholar profile](https://scholar.google.com/citations?user=rs2xJh4AAAAJ&hl=en).
